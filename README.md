# Sistema de Detecci√≥n de Intrusiones (IDS) con Machine Learning üöÄ

---

## üí° Descripci√≥n del Proyecto

Este proyecto es una implementaci√≥n de un **Sistema de Detecci√≥n de Intrusiones (IDS)** basado en **Machine Learning** utilizando Python. Su prop√≥sito fundamental es analizar el tr√°fico de red para identificar y clasificar conexiones como **"normales"** o **"ataques"**. Act√∫a como una capa crucial de seguridad, alertando sobre actividades maliciosas y patrones de comportamiento an√≥malos.

El enfoque principal de este desarrollo ha sido la optimizaci√≥n de la capacidad del modelo para **detectar el mayor n√∫mero posible de ataques reales (Recall)**, una m√©trica de rendimiento de vital importancia en el √°mbito de la ciberseguridad, donde un falso negativo (un ataque no detectado) puede tener consecuencias cr√≠ticas.

---

## üìä Dataset Utilizado: NSL-KDD

El proyecto se basa en el **Dataset NSL-KDD**, una versi√≥n mejorada y depurada del reconocido dataset KDD Cup 99. Este conjunto de datos es un est√°ndar en la investigaci√≥n de IDS, proporcionando una amplia gama de caracter√≠sticas de tr√°fico de red y clasific√°ndolas en tr√°fico normal y diversas categor√≠as de ataques (como Denegaci√≥n de Servicio - DoS, Acceso de Usuario a Root - U2R, Acceso Remoto a Local - R2L, y Probing).

Los archivos espec√≠ficos utilizados son:
* `KDDTrain+.txt` (para el entrenamiento del modelo)
* `KDDTest+.txt` (para la evaluaci√≥n del rendimiento del modelo)

**Fuente de los Datos:**
Puedes descargar estos archivos directamente desde los siguientes enlaces para replicar el entorno:
* [KDDTrain+.txt](https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain%2B.txt)
* [KDDTest+.txt](https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest%2B.txt)

---

## üõ†Ô∏è Metodolog√≠a y Desarrollo

El proceso de construcci√≥n del IDS se estructur√≥ en varias etapas fundamentales:

### 1. Carga y Exploraci√≥n Inicial de Datos
* Los datasets fueron cargados eficientemente en `DataFrames` de `pandas`.
* Se realiz√≥ una inspecci√≥n preliminar utilizando `df.head()` y `df.info()` para comprender la estructura de los datos, identificar tipos de columnas (num√©ricas vs. categ√≥ricas) y obtener un primer vistazo a la distribuci√≥n de la variable objetivo (`attack_type`).

### 2. Preprocesamiento de Datos
* **Simplificaci√≥n de la Variable Objetivo:** La columna `attack_type` se transform√≥ en una etiqueta binaria `is_attack` (donde `0` representa tr√°fico normal y `1` cualquier tipo de ataque).
* **Codificaci√≥n One-Hot (One-Hot Encoding):** Las caracter√≠sticas categ√≥ricas (`protocol_type`, `service`, `flag`) fueron convertidas a un formato num√©rico binario utilizando `pd.get_dummies()`. Se concatenaron los datasets de entrenamiento y prueba antes de este paso para asegurar la consistencia en el n√∫mero y orden de las columnas resultantes.
* **Escalado de Caracter√≠sticas:** Todas las caracter√≠sticas num√©ricas fueron estandarizadas usando `StandardScaler` de `scikit-learn`. Este paso es crucial para algoritmos sensibles a la escala, asegurando que ninguna caracter√≠stica domine desproporcionadamente debido a su rango de valores.

### 3. Entrenamiento y Evaluaci√≥n de Modelos de Machine Learning
Se experiment√≥ con diferentes algoritmos de clasificaci√≥n, evaluando su capacidad para predecir correctamente el tr√°fico de red, con un √©nfasis particular en el `Recall` para la clase de ataque.

* **√Årbol de Decisi√≥n (Decision Tree Classifier):**
    * Un modelo inicial para establecer una l√≠nea base de rendimiento.
    * **Recall de Ataques:** Aprox. 66.98%
* **Random Forest Classifier:**
    * Modelo de ensamblaje que mejora la robustez y reduce el sobreajuste.
    * Se prob√≥ una versi√≥n est√°ndar y otra con `class_weight='balanced'` para abordar el desequilibrio de clases, aunque los resultados iniciales mostraron un compromiso en el recall para este modelo espec√≠fico.
    * **Recall de Ataques (sin pesos):** Aprox. 62.58%
    * **Recall de Ataques (con pesos):** Aprox. 60.85%
* **XGBoost (Extreme Gradient Boosting Classifier):**
    * Considerado uno de los algoritmos m√°s potentes para datos tabulares. Se configur√≥ con `scale_pos_weight` para optimizar directamente el recall de la clase minoritaria (ataques).

### 4. Optimizaci√≥n de Hiperpar√°metros (GridSearchCV)
* Se utiliz√≥ `GridSearchCV` para realizar una b√∫squeda exhaustiva de la mejor combinaci√≥n de hiperpar√°metros para el `RandomForestClassifier`, con el objetivo de maximizar el `recall` en la clase de ataque mediante validaci√≥n cruzada.
* Los resultados de esta optimizaci√≥n mostraron los desaf√≠os inherentes al equilibrio entre `Precision` y `Recall` en este dataset.

---

## ‚ú® Rendimiento del Modelo Final (XGBoost)

El modelo **XGBoost Classifier** ha demostrado ser el m√°s eficaz para nuestro objetivo de IDS, logrando un balance √≥ptimo entre una alta tasa de detecci√≥n de ataques y un n√∫mero manejable de falsas alarmas.

**Matriz de Confusi√≥n del XGBoost (en el conjunto de prueba):**

[[9435  276]
[4412 8421]]


* **Verdaderos Positivos (VP):** 8421 (Ataques detectados correctamente)
* **Verdaderos Negativos (VN):** 9435 (Tr√°fico normal detectado correctamente)
* **Falsos Positivos (FP):** 276 (Tr√°fico normal clasificado err√≥neamente como Ataque - Falsas Alarmas)
* **Falsos Negativos (FN):** 4412 (Ataques reales clasificados err√≥neamente como Normal - **¬°Ataques no detectados, punto cr√≠tico a mejorar!**)

**M√©tricas de Clasificaci√≥n Clave:**

* **Recall para la detecci√≥n de ataques:** `0.6562` (65.62%)
    * Indica que el modelo fue capaz de identificar el 65.62% de todos los ataques reales presentes en el conjunto de prueba. En la detecci√≥n de intrusiones, un recall alto es de m√°xima prioridad.
* **Precisi√≥n para la detecci√≥n de ataques:** `0.9683` (96.83%)
    * Significa que cuando el modelo predice que una conexi√≥n es un ataque, tiene una fiabilidad del 96.83%. Esto resulta en un n√∫mero muy bajo de falsas alarmas, lo cual es deseable para la operativa de un IDS.

Este balance entre un **recall robusto** y una **precisi√≥n muy alta** posiciona al modelo XGBoost como una soluci√≥n s√≥lida para este sistema de detecci√≥n de intrusiones.

---

## üöÄ C√≥mo Ejecutar el Proyecto

Para poner en marcha este proyecto en tu entorno local:

1.  **Clonar el Repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/tu-nombre-repositorio.git](https://github.com/tu-usuario/tu-nombre-repositorio.git)
    cd tu-nombre-repositorio
    ```
    *(Aseg√∫rate de reemplazar `tu-usuario` y `tu-nombre-repositorio` con los datos de tu propio repositorio de GitHub.)*

2.  **Descargar los Datasets:**
    Coloca los archivos `KDDTrain+.txt` y `KDDTest+.txt` directamente en la ra√≠z de la carpeta del proyecto. Puedes descargarlos desde los enlaces proporcionados en la secci√≥n "Dataset Utilizado".

3.  **Instalar Dependencias:**
    Aseg√∫rate de tener Python 3.x instalado. Luego, instala todas las librer√≠as necesarias ejecutando el siguiente comando en tu terminal, dentro de la carpeta del proyecto:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ejecutar el Script Principal:**
    Una vez instaladas las dependencias y descargados los datasets, ejecuta el script principal:
    ```bash
    python deteccion_intrusiones.py
    ```
    El script cargar√° los datos, realizar√° el preprocesamiento, entrenar√° los modelos (√Årbol de Decisi√≥n, Random Forest, XGBoost) y mostrar√° sus m√©tricas de evaluaci√≥n en la terminal. Los modelos entrenados tambi√©n ser√°n guardados como archivos `.pkl`.

---

## üí° Futuras Mejoras y Expansi√≥n

Este proyecto representa una base s√≥lida para un IDS. Para llevarlo a un nivel superior, se podr√≠an considerar las siguientes mejoras:

* **Afinar Hiperpar√°metros:** Realizar una optimizaci√≥n m√°s exhaustiva de los hiperpar√°metros de XGBoost utilizando `RandomizedSearchCV` o herramientas avanzadas como `Optuna` para buscar un equilibrio a√∫n mejor entre `Precision` y `Recall`.
* **Manejo Avanzado de Desequilibrio de Clases:** Implementar t√©cnicas como **SMOTE (Synthetic Minority Over-sampling Technique)** o **ADASYN** para generar muestras sint√©ticas de la clase de ataque y mejorar el entrenamiento.
* **Exploraci√≥n de Modelos de Deep Learning:** Investigar la aplicaci√≥n de Redes Neuronales (ej. con TensorFlow/Keras) para la detecci√≥n de intrusiones, especialmente si los datos son muy complejos o de alta dimensionalidad.
* **An√°lisis de Importancia de Caracter√≠sticas:** Utilizar librer√≠as como SHAP o LIME para obtener una mejor interpretabilidad del modelo y entender qu√© caracter√≠sticas contribuyen m√°s a sus decisiones.
* **Despliegue y Demo:** Desarrollar una peque√±a aplicaci√≥n web (usando Flask o FastAPI) o una interfaz de usuario simple (con Streamlit) que permita cargar nuevas muestras de tr√°fico y obtener predicciones en tiempo real utilizando el modelo guardado.
* **Detecci√≥n Multi-Clase:** Extender el sistema para clasificar no solo "normal" vs. "ataque", sino los diferentes tipos de ataque (DoS, Probing, U2R, R2L).

---